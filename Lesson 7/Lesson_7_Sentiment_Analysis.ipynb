{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6361d5ae-143b-49f8-9482-155a5853fd2a",
   "metadata": {},
   "source": [
    "try a simple example showing a basic sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f564c8c-6b52-49fa-b354-c05d2574593d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: NEGATIVE, Score: 0.9992424249649048\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Sample text for sentiment analysis\n",
    "text = \"I have a headache today and feel sick\"\n",
    "\n",
    "# Perform sentiment analysis\n",
    "results = sentiment_analysis(text)\n",
    "\n",
    "# Display the sentiment analysis results\n",
    "for result in results:\n",
    "    print(f\"Sentiment: {result['label']}, Score: {result['score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45903b-b540-439c-bd2c-a843c584d07a",
   "metadata": {},
   "source": [
    "Multiple Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9feb703-a445-4ef3-ad60-da6156f92311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: POSITIVE, Score: 0.9998530149459839\n",
      "Sentiment: NEGATIVE, Score: 0.999762237071991\n",
      "Sentiment: POSITIVE, Score: 0.725955069065094\n",
      "Sentiment: POSITIVE, Score: 0.9998669624328613\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Sample text for sentiment analysis\n",
    "text = [\"It's fun to learn about AI\", \\\n",
    "        \"I'm tired today\", \\\n",
    "        \"What you talking about Willis?\",\\\n",
    "        \"This is awesome\"]\n",
    "\n",
    "# Perform sentiment analysis\n",
    "results = sentiment_analysis(text)\n",
    "\n",
    "# Display the sentiment analysis results\n",
    "for result in results:\n",
    "    print(f\"Sentiment: {result['label']}, Score: {result['score']}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4749561f-4106-4ca1-9a18-6d23e58dd6a4",
   "metadata": {},
   "source": [
    "Now try a different example - use SamLowe Roberta base to show the range of emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d892fc-0f1b-4e60-b2bb-22bdaa7928a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: disappointment, Score: 0.5985885858535767\n",
      "\n",
      "Label: neutral, Score: 0.12807415425777435\n",
      "\n",
      "Label: annoyance, Score: 0.11780586838722229\n",
      "\n",
      "Label: disapproval, Score: 0.07916329801082611\n",
      "\n",
      "Label: approval, Score: 0.06040295585989952\n",
      "\n",
      "Label: sadness, Score: 0.05712652578949928\n",
      "\n",
      "Label: realization, Score: 0.029038047417998314\n",
      "\n",
      "Label: admiration, Score: 0.014047041535377502\n",
      "\n",
      "Label: joy, Score: 0.010527268052101135\n",
      "\n",
      "Label: love, Score: 0.00786681566387415\n",
      "\n",
      "Label: desire, Score: 0.007092220243066549\n",
      "\n",
      "Label: relief, Score: 0.00646816473454237\n",
      "\n",
      "Label: remorse, Score: 0.006235772743821144\n",
      "\n",
      "Label: embarrassment, Score: 0.005847088061273098\n",
      "\n",
      "Label: disgust, Score: 0.005842560902237892\n",
      "\n",
      "Label: anger, Score: 0.005499107763171196\n",
      "\n",
      "Label: optimism, Score: 0.005481374450027943\n",
      "\n",
      "Label: caring, Score: 0.002917974255979061\n",
      "\n",
      "Label: pride, Score: 0.0025856036227196455\n",
      "\n",
      "Label: excitement, Score: 0.00253599276766181\n",
      "\n",
      "Label: nervousness, Score: 0.0025077154859900475\n",
      "\n",
      "Label: confusion, Score: 0.002501984592527151\n",
      "\n",
      "Label: grief, Score: 0.0019851604010909796\n",
      "\n",
      "Label: gratitude, Score: 0.0015377964591607451\n",
      "\n",
      "Label: surprise, Score: 0.0010222513228654861\n",
      "\n",
      "Label: amusement, Score: 0.0009379801922477782\n",
      "\n",
      "Label: curiosity, Score: 0.0009175455779768527\n",
      "\n",
      "Label: fear, Score: 0.0006190796848386526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "\n",
    "sentences = [\"I have a really nice training today, but the screen froze a few times and got some dislikes\"]\n",
    "\n",
    "model_outputs = classifier(sentences)\n",
    "\n",
    "# Print each output on a new line with a carriage return after each line\n",
    "for output in model_outputs[0]:\n",
    "    print(f\"Label: {output['label']}, Score: {output['score']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a2dd8-54d7-4996-bee1-00b8af22c0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
